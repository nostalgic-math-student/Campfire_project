{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i3vzfV9MnP9F"
      },
      "outputs": [],
      "source": [
        "#!pip install colab-xterm\n",
        "#%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W4I6DdEgkkQS"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc9e4fTJmTX7",
        "outputId": "78ecabe5-4a77-4b79-c1eb-248962871e52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: ipfs_bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: ipfs_bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully fetched file from IPFS (CID: bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: ipfs_bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: ipfs_bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Document from IPFS stored in ChromaDB.\n"
          ]
        }
      ],
      "source": [
        "# Initialize ChromaDB\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# Define the embedding model (Use OpenAI's API)\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=\"OPENAI-API-KEY\", model_name=\"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "# Create or retrieve the ChromaDB collection\n",
        "collection = chroma_client.get_or_create_collection(name=\"knowledge_base\", embedding_function=openai_ef)\n",
        "\n",
        "def fetch_ipfs(cid):\n",
        "    \"\"\"Retrieve a file from IPFS given its CID.\"\"\"\n",
        "    url = f\"https://ipfs.io/ipfs/{cid}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"‚úÖ Successfully fetched file from IPFS (CID: {cid})\")\n",
        "        return response.text\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Error fetching IPFS CID {cid}\")\n",
        "        return None\n",
        "\n",
        "# Example CID (Replace with your actual CID)\n",
        "ipfs_cid = \"bafkreih2myueo4kzqnhc3kltxw3vt3c3ir6tts7smlqwaex4izmkutf5zq\"\n",
        "\n",
        "# Fetch document from IPFS\n",
        "document_text = fetch_ipfs(ipfs_cid)\n",
        "\n",
        "if document_text:\n",
        "    # Store the document in ChromaDB\n",
        "    doc_id = f\"ipfs_{ipfs_cid}\"  # Unique ID for the document\n",
        "    collection.add(ids=[doc_id], documents=[document_text], metadatas=[{\"source\": \"ipfs\", \"cid\": ipfs_cid}])\n",
        "    print(\"‚úÖ Document from IPFS stored in ChromaDB.\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to retrieve document from IPFS.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zITlhWDRdHy",
        "outputId": "3d57a311-11d5-4ca2-d3cd-0c88f3e8d513"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîé Relevant documents found: ['esta es una propuesta', 'Titulo de novela \"Phiro\"\\r\\nPhiro\\r\\nUna caja de f√≥sforos que tenia veinticinco f√≥sforos dentro, ten√≠a uno llamado Phiro el cual estaba debajo de los dem√°s en la cajetilla de f√≥sforos y ansiaba saber que pasar√≠a cuando lo sacaran, pasaba cada d√≠a esperando en la eterna oscuridad viendo como sacaban uno a uno a sus hermanos, hasta que un d√≠a por fin lo sacaron y todo estaba igual de oscuro que dentro de la caja pero cuando lo pasaron por la caja‚Ä¶ por unos breves segundos fue feliz ya que acab√≥ con toda la oscuridad que hab√≠a a su alrededor e ilumino el rostro feliz de una ni√±a.\\r\\n']\n"
          ]
        }
      ],
      "source": [
        "## Test: Retrieve docs from Database to make sure CIDS were stored correctly\n",
        "def retrieve_relevant_docs(query, top_k=3):\n",
        "    \"\"\"Fetch relevant documents from ChromaDB for a given query.\"\"\"\n",
        "    results = collection.query(query_texts=[query], n_results=top_k)\n",
        "    return results[\"documents\"][0] if results[\"documents\"] else []\n",
        "\n",
        "# Example query\n",
        "query_text = \"¬øQu√© informaci√≥n contiene el archivo de IPFS?\"\n",
        "retrieved_docs = retrieve_relevant_docs(query_text)\n",
        "\n",
        "# Print results\n",
        "print(f\"üîé Relevant documents found: {retrieved_docs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WizYHD0GrgAB"
      },
      "outputs": [],
      "source": [
        "### Test\n",
        "import os\n",
        "import time\n",
        "import psutil\n",
        "import requests\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "from threading import Thread\n",
        "import ollama\n",
        "\n",
        "# Initialize ChromaDB\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=\"OPENAI-API-KEY\", model_name=\"text-embedding-ada-002\"\n",
        ")\n",
        "collection = chroma_client.get_or_create_collection(name=\"knowledge_base\", embedding_function=openai_ef)\n",
        "\n",
        "# Define FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Request schemas\n",
        "class ChatRequest(BaseModel):\n",
        "    messages: list\n",
        "    model: str = \"mistral\"\n",
        "    temperature: float = 0.7\n",
        "\n",
        "class AddCIDRequest(BaseModel):\n",
        "    cid: str\n",
        "\n",
        "# Helper functions\n",
        "def is_port_in_use(port=8000):\n",
        "    \"\"\"Check if a port is in use.\"\"\"\n",
        "    for proc in psutil.process_iter(attrs=[\"connections\"]):\n",
        "        for conn in proc.info[\"connections\"] if proc.info[\"connections\"] else []:\n",
        "            if conn.laddr.port == port:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def fetch_ipfs(cid):\n",
        "    \"\"\"Retrieve a file from IPFS given its CID.\"\"\"\n",
        "    url = f\"https://ipfs.io/ipfs/{cid}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"‚úÖ Successfully fetched file from IPFS (CID: {cid})\")\n",
        "        print(f\"TEXTO DOCUMENTO {str(response.text)}\")\n",
        "        return response.text\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Error fetching IPFS CID {cid}\")\n",
        "        return None\n",
        "\n",
        "# Endpoints\n",
        "@app.post(\"/api/v1/add_cid\")\n",
        "def add_cid(request: AddCIDRequest):\n",
        "  try:\n",
        "    cid = request.cid\n",
        "    stored_cids = collection.get()[\"metadatas\"]\n",
        "    stored_cids = [item[\"cid\"] for item in stored_cids] if stored_cids else []\n",
        "    if cid in stored_cids:\n",
        "        return {\"status\": \"‚ùå CID already exists in ChromaDB\", \"cid\": cid}\n",
        "\n",
        "    document_text = fetch_ipfs(cid)\n",
        "    if document_text:\n",
        "        doc_id = f\"ipfs_{cid}\"\n",
        "        collection.add(ids=[doc_id], documents=[document_text], metadatas=[{\"source\": \"ipfs\", \"cid\": cid}])\n",
        "        return {\"status\": \"‚úÖ CID added to ChromaDB\", \"cid\": cid}\n",
        "    else:\n",
        "        raise HTTPException(status_code=404, detail=\"Failed to fetch CID from IPFS\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error en CID no esperado {e}\")\n",
        "\n",
        "@app.post(\"/api/v1/chat\")\n",
        "def chat(request: ChatRequest):\n",
        "    query = request.messages[-1][\"content\"]  # Extraer la consulta del usuario\n",
        "    stored_docs = collection.count()  # Contar documentos en la colecci√≥n de ChromaDB\n",
        "    top_k = min(2, stored_docs)  # Limitar el n√∫mero de resultados relevantes\n",
        "\n",
        "    # Generar el contexto desde ChromaDB\n",
        "    if top_k == 0:\n",
        "        context = \"No relevant data found.\"\n",
        "    else:\n",
        "        # Consultar ChromaDB\n",
        "        results = collection.query(query_texts=[query], n_results=top_k)\n",
        "        context = \"\\n\".join(results[\"documents\"][0]) if results[\"documents\"] else \"No relevant data found.\"\n",
        "\n",
        "    # A√±adir el contexto como informaci√≥n del sistema\n",
        "    request.messages.insert(0, {\"role\": \"system\", \"content\": f\"Use the following information to answer:\\n{context}\"})\n",
        "\n",
        "    # Llamar a Ollama para generar la respuesta basada en los mensajes y el contexto\n",
        "    try:\n",
        "        response = ollama.chat(\n",
        "            model=request.model,\n",
        "            messages=request.messages,\n",
        "            options={\"temperature\": request.temperature}\n",
        "        )\n",
        "        return {\"response\": response[\"message\"][\"content\"]}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD6CxrI218fA",
        "outputId": "309510ba-86bc-465f-c304-143355a8d820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Restarting Uvicorn...\n",
            "üîÑ Starting ngrok...\n",
            "üî• Public API URL: https://e67c-35-243-235-7.ngrok-free.app\n",
            "üîÑ Keeping the Google Colab session alive...\n",
            "üîÑ Restarting ngrok...\n",
            "üî• Public API URL: https://7cb4-35-243-235-7.ngrok-free.app\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"POST /api/v1/chat HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2806:2f0:9261:cc05:585e:ebc8:cc45:2326:0 - \"GET /docs HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# Server and ngrok functions\n",
        "def start_uvicorn():\n",
        "    \"\"\"Run Uvicorn directly.\"\"\"\n",
        "    if is_port_in_use(8000):\n",
        "        print(\"üöÄ Restarting Uvicorn...\")\n",
        "    else:\n",
        "        print(\"‚úÖ Uvicorn is starting.\")\n",
        "        uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "def restart_ngrok():\n",
        "    \"\"\"Keep ngrok tunnel active.\"\"\"\n",
        "    while True:\n",
        "        if is_port_in_use(8000):\n",
        "            try:\n",
        "                print(\"üîÑ Restarting ngrok...\")\n",
        "                os.system(\"pkill -f ngrok\")\n",
        "                time.sleep(3)\n",
        "                global public_url\n",
        "                public_url = ngrok.connect(8000).public_url\n",
        "                print(f\"üî• Public API URL: {public_url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error restarting ngrok: {e}\")\n",
        "        else:\n",
        "            print(\"‚ùå Uvicorn is not running. Fix it before restarting ngrok.\")\n",
        "            start_uvicorn()\n",
        "        time.sleep(1800)  # Renew every 30 minutes\n",
        "\n",
        "# Run server and ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    # Start Uvicorn in a separate thread\n",
        "    Thread(target=start_uvicorn).start()\n",
        "    time.sleep(5)  # Wait for Uvicorn to start\n",
        "\n",
        "    # Start ngrok if Uvicorn is running\n",
        "    if is_port_in_use(8000):\n",
        "        print(\"üîÑ Starting ngrok...\")\n",
        "        public_url = ngrok.connect(8000).public_url\n",
        "        print(f\"üî• Public API URL: {public_url}\")\n",
        "    else:\n",
        "        print(\"‚ùå Uvicorn failed to start. Check manually.\")\n",
        "\n",
        "    # Keep renewing ngrok in a separate thread\n",
        "    Thread(target=restart_ngrok).start()\n",
        "\n",
        "    # Keep the session alive\n",
        "    while True:\n",
        "        print(\"üîÑ Keeping the Google Colab session alive...\")\n",
        "        time.sleep(600)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
